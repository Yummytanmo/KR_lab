{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XuXWJLEm2UWS"
   },
   "source": [
    "# Part1 **图节点表示实验**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8gzsP50bF6Gb"
   },
   "source": [
    "\n",
    "在第一部分实验，我们将编写**节点表示学习**的整个流程，我们将进行3步\n",
    "\n",
    "第一步 我们先加载经典社交网络图 [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club). 并探索这个图上的多种统计信息。\n",
    "\n",
    "接着我们尝试将图结构转化成tensor形式，为我们进一步在图上进行机器学习算法做准备\n",
    "\n",
    "最后，我们将实现首个图算法：一个图节点表示模型。\n",
    "\n",
    "**注意**: 确保 **顺序运行每个section的代码**, 这样所有临时变量或包才能被保留到下个cell "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nwwq0nSdmsOL"
   },
   "source": [
    "# Graph basics\n",
    "首先，我们将加载一个网络学中经典的图，[karate club network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club).我们将探索这个图的多个统计。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FDkpByYYfSzb"
   },
   "source": [
    "## Setup\n",
    "这个实验中，我们需要大量使用network这个包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWPkJjPAfVNW"
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VqUnYT5qUZYh"
   },
   "source": [
    "## Zachary's karate club network\n",
    "\n",
    "[Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club)是一个社交网络图，它描述了一个由34个空手道俱乐部成员组成的社会网络，并记录了在俱乐部外互动的成员之间的联系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIETqEfrfy5Y",
    "outputId": "2623ce12-3754-45b7-cea8-ab95a8afc18f"
   },
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "\n",
    "# G is an undirected graph\n",
    "type(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "hDvf3nm-ors4",
    "outputId": "7855192c-40b6-4265-c812-4231a23afcd4"
   },
   "outputs": [],
   "source": [
    "# Visualize the graph\n",
    "nx.draw(G, with_labels = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FX25Y1CrYmgN"
   },
   "source": [
    "## Question 1: karate club network的 average degree(平均度)是多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUhES1VYo3tB",
    "outputId": "06d76191-e3cd-4ee3-a076-29efea992c0b"
   },
   "outputs": [],
   "source": [
    "def average_degree(num_edges, num_nodes):\n",
    "  # TODO: Implement this function that takes number of edges\n",
    "  # and number of nodes, and returns the average node degree of\n",
    "  # the graph. Round the result to nearest integer (for example\n",
    "  # 3.3 will be rounded to 3 and 3.7 will be rounded to 4)\n",
    "\n",
    "  avg_degree = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  avg_degree = 2*num_edges/num_nodes\n",
    "  avg_degree = round(avg_degree)\n",
    "  #########################################\n",
    "\n",
    "  return avg_degree\n",
    "\n",
    "num_edges = G.number_of_edges()\n",
    "num_nodes = G.number_of_nodes()\n",
    "avg_degree = average_degree(num_edges, num_nodes)\n",
    "print(\"Average degree of karate club network is {}\".format(avg_degree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk02fD4vYmZI"
   },
   "source": [
    "## Question 2: karate club网络的平均聚类系数是多少k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k15XKEto1aYJ",
    "outputId": "9969362d-9481-45fa-e9a4-9ba59346c8a6"
   },
   "outputs": [],
   "source": [
    "def average_clustering_coefficient(G):\n",
    "  # TODO: Implement this function that takes a nx.Graph\n",
    "  # and returns the average clustering coefficient. Round\n",
    "  # the result to 2 decimal places (for example 3.333 will\n",
    "  # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n",
    "\n",
    "  avg_cluster_coef = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## Note:\n",
    "  ## 1: Please use the appropriate NetworkX clustering function\n",
    "  a = nx.clustering(G)\n",
    "  avg_cluster_coef = sum(a.values())/len(a)\n",
    "  avg_cluster_coef = round(avg_cluster_coef,2)\n",
    "  #########################################\n",
    "\n",
    "  return avg_cluster_coef\n",
    "\n",
    "avg_cluster_coef = average_clustering_coefficient(G)\n",
    "print(\"Average clustering coefficient of karate club network is {}\".format(avg_cluster_coef))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zghQ-AhXYmP4"
   },
   "source": [
    "## Question 3: 在一次PageRank迭代之后，节点0 (id为0的节点)的PageRank值是多少?\n",
    "\n",
    "PageRank使用网络的链接结构来衡量图中节点的重要性。来自重要页面的“vote”更有价值。特殊的，当一个重要程度为 $r_i$ 的页面 $i$ 具有 $d_i$ 个外部链接, 那么每个链接将会得到 $\\frac{r_i}{d_i}$ 的“vote”. 因此一个页面 $j$的重要程度, 记为 $r_j$ ，是他所有链接的总和\n",
    "$$r_j = \\sum_{i \\rightarrow j} \\frac{r_i}{d_i}$$\n",
    "\n",
    ", 其中 $d_i$ 是节点 $i$ 的出度.\n",
    "\n",
    "PageRank算法(由Google使用)输出一个概率分布，表示随机浏览者点击链接到达任何特定页面的可能性。在每个时间步，随机的冲浪者有两个选择：\n",
    "- $\\beta$ 的概率随机跟随一个页面\n",
    "- $1- \\beta$ 的概率随机跳转到一个页面\n",
    "\n",
    "因此，一个特定页面的重要性由下面的pagerank等式计算：\n",
    " $$r_j = \\sum_{i \\rightarrow j} \\beta \\frac{r_i}{d_i} + (1 - \\beta) \\frac{1}{N}$$\n",
    "\n",
    "请通过实现节点0的上述PageRank方程来完成代码块。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOGdWjNc6O7x",
    "outputId": "d92117f5-f5bc-4a0c-863e-1c2efb2bd900"
   },
   "outputs": [],
   "source": [
    "print(dir(G)) # to see the available functions and attributes\n",
    "def one_iter_pagerank(G, beta, r0, node_id):\n",
    "  # TODO: Implement this function that takes a nx.Graph, beta, r0 and node id.\n",
    "  # The return value r1 is one interation PageRank value for the input node.\n",
    "  # Please round r1 to 2 decimal places.\n",
    "\n",
    "  r1 = 0\n",
    "  print(G.edges(node_id))\n",
    "  print(G.degree(node_id))\n",
    "  print(G.neighbors(node_id))\n",
    "  print(G.number_of_nodes())\n",
    "  ############# Your code here ############\n",
    "  ## Note:\n",
    "  ## 1: You should not use nx.pagerank\n",
    "  \n",
    "  for i in G.neighbors(node_id):\n",
    "    r1 += r0/G.degree(i)\n",
    "  r1 = beta*r1 + (1-beta)/G.number_of_nodes()\n",
    "  r1 = round(r1,2)\n",
    "  #########################################\n",
    "\n",
    "  return r1\n",
    "\n",
    "beta = 0.8\n",
    "r0 = 1 / G.number_of_nodes()\n",
    "node = 0\n",
    "r1 = one_iter_pagerank(G, beta, r0, node)\n",
    "print(\"The PageRank value for node 0 after one iteration is {}\".format(r1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-MxvowibYl4x"
   },
   "source": [
    "# 2 Graph to Tensor\n",
    "我们将一起将图$G$转换为PyTorch tensor，这样我们就可以在图上执行机器学习。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eDA8PosrA-9V"
   },
   "source": [
    "## Setup\n",
    "检查Pytorch是否安装好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntuPVat_BAf1",
    "outputId": "5854be5f-c049-4169-fb45-cc240e8738ae"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fko_2wSKYlun"
   },
   "source": [
    "## PyTorch tensor 基础\n",
    "\n",
    "我们可以生成全0、1或随机值的PyTorch张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2ySw3m-A9qF",
    "outputId": "068b3365-0d68-4f33-ae19-31e7864603f9"
   },
   "outputs": [],
   "source": [
    "# Generate 3 x 4 tensor with all ones\n",
    "ones = torch.ones(3, 4)\n",
    "print(ones)\n",
    "\n",
    "# Generate 3 x 4 tensor with all zeros\n",
    "zeros = torch.zeros(3, 4)\n",
    "print(zeros)\n",
    "\n",
    "# Generate 3 x 4 tensor with random values on the interval [0, 1)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "print(random_tensor)\n",
    "\n",
    "# Get the shape of the tensor\n",
    "print(ones.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "x8mp66eHBxWC"
   },
   "source": [
    "PyTorch张量包含一个数据类型`dtype`的元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQiOvKJJBwq4",
    "outputId": "3f27dee5-3e8f-4ae7-e844-2c1ce266a067"
   },
   "outputs": [],
   "source": [
    "# Create a 3 x 4 tensor with all 32-bit floating point zeros\n",
    "zeros = torch.zeros(3, 4, dtype=torch.float32)\n",
    "print(zeros.dtype)\n",
    "\n",
    "# Change the tensor dtype to 64-bit integer\n",
    "zeros = zeros.type(torch.long)\n",
    "print(zeros.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "I9EfegIRDkk2"
   },
   "source": [
    "## Question 4: 获取karate club network的边列表并将其转换为 `torch.LongTensor`.  `pos_edge_index` tensor的 `torch.sum` 值是多少?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEtVxMFID3ZT",
    "outputId": "906df88b-cc12-4ff3-d8ac-268bd09fb02d"
   },
   "outputs": [],
   "source": [
    "def graph_to_edge_list(G):\n",
    "  # TODO: Implement the function that returns the edge list of\n",
    "  # an nx.Graph. The returned edge_list should be a list of tuples\n",
    "  # where each tuple is a tuple representing an edge connected\n",
    "  # by two nodes.\n",
    "\n",
    "  edge_list = []\n",
    "\n",
    "  ############# Your code here ############\n",
    "  edge_list = list(G.edges())\n",
    "  #########################################\n",
    "\n",
    "  return edge_list\n",
    "\n",
    "def edge_list_to_tensor(edge_list):\n",
    "  # TODO: Implement the function that transforms the edge_list to\n",
    "  # tensor. The input edge_list is a list of tuples and the resulting\n",
    "  # tensor should have the shape [2, len(edge_list)].\n",
    "\n",
    "  edge_index = torch.tensor([])\n",
    "\n",
    "  ############# Your code here ############\n",
    "  edge_index = torch.tensor(edge_list).t()\n",
    "  #########################################\n",
    "\n",
    "  return edge_index\n",
    "\n",
    "pos_edge_list = graph_to_edge_list(G)\n",
    "print(pos_edge_list)\n",
    "pos_edge_index = edge_list_to_tensor(pos_edge_list)\n",
    "print(\"The pos_edge_index tensor has shape {}\".format(pos_edge_index.shape))\n",
    "print(\"The pos_edge_index tensor has sum value {}\".format(torch.sum(pos_edge_index)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UBL-ZmdHWqIu"
   },
   "source": [
    "## Question 5: 请实现以下对负边进行采样的函数。然后回答哪些边(edge_1到edge_5)是karate club network中的负边?\n",
    "\n",
    "“负”边是指图中不存在的边/链接。“负”一词是从链路预测中的“负抽样”借来的。这与边的权值无关。\n",
    "\n",
    "例如，给定一条边(src, dst)，您应该检查(src, dst)和(dst, src)都不是图中的边。如果这些都成立，那么它就是一条负边。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9N8VT1f8-IJ8",
    "outputId": "fbcb187a-b866-4f3a-cff8-33ba22ef3616"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_negative_edges(G, num_neg_samples):\n",
    "  # TODO: Implement the function that returns a list of negative edges.\n",
    "  # The number of sampled negative edges is num_neg_samples. You do not\n",
    "  # need to consider the corner case when the number of possible negative edges\n",
    "  # is less than num_neg_samples. It should be ok as long as your implementation\n",
    "  # works on the karate club network. In this implementation, self loops should\n",
    "  # not be considered as either a positive or negative edge. Also, notice that\n",
    "  # the karate club network is an undirected graph, if (0, 1) is a positive\n",
    "  # edge, do you think (1, 0) can be a negative one?\n",
    "\n",
    "  neg_edge_list = []\n",
    "\n",
    "  ############# Your code here ############\n",
    "\n",
    "  while len(neg_edge_list) < num_neg_samples:\n",
    "    a = random.randint(0, G.number_of_nodes()-1)\n",
    "    b = random.randint(0, G.number_of_nodes()-1)\n",
    "    if a!=b and (a,b) not in G.edges():\n",
    "      neg_edge_list.append((a,b))\n",
    "  #########################################\n",
    "\n",
    "  return neg_edge_list\n",
    "\n",
    "# Sample 78 negative edges\n",
    "neg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n",
    "\n",
    "# Transform the negative edge list to tensor\n",
    "neg_edge_index = edge_list_to_tensor(neg_edge_list)\n",
    "print(\"The neg_edge_index tensor has shape {}\".format(neg_edge_index.shape))\n",
    "\n",
    "# Which of following edges can be negative ones?\n",
    "edge_1 = (7, 1)\n",
    "edge_2 = (1, 33)\n",
    "edge_3 = (33, 22)\n",
    "edge_4 = (0, 4)\n",
    "edge_5 = (4, 2)\n",
    "\n",
    "############# Your code here ############\n",
    "## Note:\n",
    "## 1: For each of the 5 edges, print whether it can be negative edge\n",
    "def is_negative_edge(G, edge):\n",
    "  return True if edge not in G.edges() else False\n",
    "\n",
    "for edge in [edge_1, edge_2, edge_3, edge_4, edge_5]:\n",
    "  print(\"Edge {} is a negative edge: {}\".format(edge, is_negative_edge(G, edge)))\n",
    "#########################################\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wk9Q-a-9qGsw"
   },
   "source": [
    "# 3 节点表示学习\n",
    "\n",
    "最后，我们将完成图的第一个学习算法:节点嵌入模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDBxRQcZ_dUH"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lnqn9H6s_ehX",
    "outputId": "12246b72-3766-4256-9a39-51116e442c56"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6gomAf8vxq0R"
   },
   "source": [
    "为了编写我们自己的节点表示学习方法，我们将会大量使用[`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) 模块（pytorch版）. 我们来学习如何使用 `nn.Embedding`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRiWGuLAx5yx",
    "outputId": "244cd9b9-2c87-47b1-9ed2-203157957c32"
   },
   "outputs": [],
   "source": [
    "# Initialize an embedding layer\n",
    "# Suppose we want to have embedding for 4 items (e.g., nodes)\n",
    "# Each item is represented with 8 dimensional vector\n",
    "\n",
    "emb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\n",
    "print('Sample embedding layer: {}'.format(emb_sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bS9qQfeujEVh"
   },
   "source": [
    "我们可以使用tensor下标从嵌入矩阵中选择项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AGIfP4QEDr8",
    "outputId": "2e3ca206-d10f-44c1-b9f6-09cfdaeb02fc"
   },
   "outputs": [],
   "source": [
    "# Select an embedding in emb_sample\n",
    "id = torch.LongTensor([1])\n",
    "print(emb_sample(id))\n",
    "\n",
    "# Select multiple embeddings\n",
    "ids = torch.LongTensor([1, 3])\n",
    "print(emb_sample(ids))\n",
    "\n",
    "# Get the shape of the embedding weight matrix\n",
    "shape = emb_sample.weight.data.shape\n",
    "print(shape)\n",
    "\n",
    "# Overwrite the weight to tensor with all ones\n",
    "emb_sample.weight.data = torch.ones(shape)\n",
    "\n",
    "# Let's check if the emb is indeed initilized\n",
    "ids = torch.LongTensor([0, 3])\n",
    "print(emb_sample(ids))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8MjBuDKaKIsM"
   },
   "source": [
    "## Question 6:现在来为我们已有的图创造embedding\n",
    "- 我们想要karate club network 每个节点的 **16 dimensional** 向量表示\n",
    "- 我们想用 **uniform distribution** （均匀分布）初始化矩阵, 在 $[0, 1)$ 范围内. 建议使用 [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "hMszSwRPKGn1",
    "outputId": "8ff51aec-8a80-4282-ee7a-b0fb0658e460"
   },
   "outputs": [],
   "source": [
    "# Please do not change / reset the random seed\n",
    "torch.manual_seed(1)\n",
    "\n",
    "def create_node_emb(num_node=34, embedding_dim=16):\n",
    "  # TODO: Implement this function that will create the node embedding matrix.\n",
    "  # A torch.nn.Embedding layer will be returned. You do not need to change\n",
    "  # the values of num_node and embedding_dim. The weight matrix of returned\n",
    "  # layer should be initialized under uniform distribution.\n",
    "\n",
    "  emb = None\n",
    "\n",
    "  ############# Your code here ############\n",
    "  emb = nn.Embedding(num_embeddings=num_node, embedding_dim=embedding_dim)\n",
    "  emb.weight.data = torch.rand(num_node, embedding_dim)\n",
    "  #########################################\n",
    "\n",
    "  return emb\n",
    "\n",
    "emb = create_node_emb()\n",
    "ids = torch.LongTensor([0, 3])\n",
    "\n",
    "# Print the embedding layer\n",
    "print(\"Embedding: {}\".format(emb))\n",
    "\n",
    "# An example that gets the embeddings for node 0 and 3\n",
    "print(emb(ids).shape )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4QfoANibTzyh"
   },
   "source": [
    "## 可视化初始节点表示\n",
    "理解嵌入矩阵的一个好方法是在二维空间中可视化它。\n",
    "在这里，我们实现了一个嵌入可视化功能。\n",
    "我们首先使用PCA将嵌入的维数降至二维空间。\n",
    "然后我们可视化每个点，用它所属的集群来着色。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LCoIkarhfYD"
   },
   "outputs": [],
   "source": [
    "def visualize_emb(emb):\n",
    "  X = emb.weight.data.numpy()\n",
    "  pca = PCA(n_components=2)\n",
    "  components = pca.fit_transform(X)\n",
    "  plt.figure(figsize=(6, 6))\n",
    "  club1_x = []\n",
    "  club1_y = []\n",
    "  club2_x = []\n",
    "  club2_y = []\n",
    "  for node in G.nodes(data=True):\n",
    "    if node[1]['club'] == 'Mr. Hi':\n",
    "      club1_x.append(components[node[0]][0])\n",
    "      club1_y.append(components[node[0]][1])\n",
    "    else:\n",
    "      club2_x.append(components[node[0]][0])\n",
    "      club2_y.append(components[node[0]][1])\n",
    "  plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n",
    "  plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "# Visualize the initial random embeddding\n",
    "visualize_emb(emb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bQIyuEz9ANb2"
   },
   "source": [
    "## Question 7: 训练表示：你能得到的最好表示是什么?请在实验报告上记录最佳损失和准确性。\n",
    "\n",
    "我们想要优化我们的嵌入来完成将边缘分类为正或负的任务。给定一条边和每个节点的嵌入，嵌入的点积，后面跟着一个sigmoid，应该给我们该边为正的可能性(sigmoid的输出>0.5)或负(sigmoid < 0.5)。\n",
    "\n",
    "注意，我们使用的是您在前面的问题中编写的函数，以及在前面的单元格中初始化的变量。如果你遇到问题，确保你对问题1-6的答案是正确的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDeQTNNxqH0j"
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "import torch.nn as nn\n",
    "\n",
    "def accuracy(pred, label):\n",
    "  # TODO: Implement the accuracy function. This function takes the\n",
    "  # pred tensor (the resulting tensor after sigmoid) and the label\n",
    "  # tensor (torch.LongTensor). Predicted value greater than 0.5 will\n",
    "  # be classified as label 1. Else it will be classified as label 0.\n",
    "  # The returned accuracy should be rounded to 4 decimal places.\n",
    "  # For example, accuracy 0.82956 will be rounded to 0.8296.\n",
    "\n",
    "  accu = 0.0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  pred = (pred>0.5).float()\n",
    "  accu = (pred == label).float().mean().item()\n",
    "  accu = round(accu,4)\n",
    "  #########################################\n",
    "\n",
    "  return accu\n",
    "\n",
    "def train(emb, loss_fn, sigmoid, train_label, train_edge):\n",
    "  # TODO: Train the embedding layer here. You can also change epochs and\n",
    "  # learning rate. In general, you need to implement:\n",
    "  # (1) Get the embeddings of the nodes in train_edge\n",
    "  # (2) Dot product the embeddings between each node pair\n",
    "  # (3) Feed the dot product result into sigmoid\n",
    "  # (4) Feed the sigmoid output into the loss_fn\n",
    "  # (5) Print both loss and accuracy of each epoch\n",
    "  # (6) Update the embeddings using the loss and optimizer\n",
    "  # (as a sanity check, the loss should decrease during training)\n",
    "\n",
    "  epochs = 500\n",
    "  learning_rate = 0.1\n",
    "\n",
    "  optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "  for i in range(epochs):\n",
    "\n",
    "    ############# Your code here ############\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # (1) Get the embeddings of the nodes in train_edge\n",
    "    emb_edge = emb(train_edge)\n",
    "    # (2) Dot product the embeddings between each node pair\n",
    "    pred = (emb_edge[0] * emb_edge[1]).sum(dim=1)\n",
    "    # (3) Feed the dot product result into sigmoid\n",
    "    pred = sigmoid(pred)\n",
    "    # (4) Feed the sigmoid output into the loss_fn\n",
    "    loss = loss_fn(pred, train_label)\n",
    "    # (5) Print both loss and accuracy of each epoch\n",
    "    print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(i, loss.item(), accuracy(pred, train_label)))\n",
    "    # (6) Update the embeddings using the loss and optimizer\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #########################################\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "print(pos_edge_index.shape)\n",
    "\n",
    "# Generate the positive and negative labels\n",
    "pos_label = torch.ones(pos_edge_index.shape[1], )\n",
    "neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
    "\n",
    "# Concat positive and negative labels into one tensor\n",
    "train_label = torch.cat([pos_label, neg_label], dim=0)\n",
    "\n",
    "# Concat positive and negative edges into one tensor\n",
    "# Since the network is very small, we do not split the edges into val/test sets\n",
    "train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
    "print(train_edge.shape)\n",
    "train(emb, loss_fn, sigmoid, train_label, train_edge)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WX2PSXnTDiNi"
   },
   "source": [
    "## 可视化最终的节点表示\n",
    "在这里可视化节点最终表示，可以直观地将该图与之前的嵌入图进行比较。\n",
    "训练后，你会发现这两个班的分离更加明显了。\n",
    "这也是对代码实现的一个很好的完整性检查。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtNgl4VhYKow"
   },
   "outputs": [],
   "source": [
    "# Visualize the final learned embedding\n",
    "visualize_emb(emb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XuXWJLEm2UWS"
   },
   "source": [
    "# **Part 2 GNN**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8gzsP50bF6Gb"
   },
   "source": [
    "在Part 2中，我们将使用PyTorch Geometric (PyG)构建我们自己的图神经网络，然后将该模型应用于两个Open graph Benchmark (OGB)数据集。这两个数据集将用于在两个不同的基于图的任务上对模型的性能进行基准测试:1)节点属性预测，预测单个节点的属性;2)图属性预测，预测整个图或子图的属性。\n",
    "\n",
    "首先，我们将学习PyTorch Geometric如何将图存储为PyTorch张量。\n",
    "\n",
    "然后，我们将使用`ogb`包加载和检查开放图形基准(OGB)数据集之一。OGB是一个现实的、大规模的、不同的基准数据集的集合，用于图上的机器学习。`ogb`包不仅为每个数据集提供数据加载器，还提供模型评估器。\n",
    "\n",
    "最后，我们将使用PyTorch Geometric构建我们自己的图神经网络。然后，我们将在OGB节点属性预测和图属性预测任务上训练和评估我们的模型。\n",
    "\n",
    "\n",
    "**注意**: 确保 **顺序运行每个section的代码**, 这样所有临时变量或包才能被保留到下个cell \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGKqVEbbMEzf"
   },
   "source": [
    "# Device\n",
    "\n",
    "可能需要gpu来加速图神经网络训练"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OCK7krJdp4o8"
   },
   "source": [
    "# Setup\n",
    "首先让我们检查你正在运行的PyTorch的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2vkP8pA1qBE5",
    "outputId": "38f57e01-cac9-4c76-e6c8-aa3b32d9f336"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "L6d22O6DqGSZ"
   },
   "source": [
    "下载PyG所需的软件包。确保您的torch版本与上面单元的输出相匹配。如果有任何问题，可以在[PyG's installation page](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)上找到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zr8hfxJ-qRg2",
    "outputId": "de1c4e05-7888-4d88-ebbb-e9eba4f5a943"
   },
   "outputs": [],
   "source": [
    "# Install torch geometric\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  torch_version = str(torch.__version__)\n",
    "  scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "  sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "  !pip install torch-scatter -f $scatter_src\n",
    "  !pip install torch-sparse -f $sparse_src\n",
    "  !pip install torch-geometric\n",
    "  !pip install ogb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nwwq0nSdmsOL"
   },
   "source": [
    "# 1) PyTorch Geometric (Datasets and Data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf7vUmdNKCjA"
   },
   "source": [
    "PyTorch Geometric有两个类用于存储和/或将图形转换为tensor格式。一个是`torch_geometric.dataset` ，其中包含各种常见的图形数据集。另一个是`torch_geometric.data `，它提供PyTorch张量中图形的数据处理。\n",
    "\n",
    "在本节中，我们将学习如何使用`torch_geometric.dataset`和`torch_geometric.data`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ic-o1P3r6hr2"
   },
   "source": [
    "## PyG Datasets\n",
    "\n",
    "`torch_geometric.datasets` 类有很多常用的图数据集. 我们将使用一个示例数据集探索它的用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zT5qca3x6XpG"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  root = './enzymes'\n",
    "  name = 'ENZYMES'\n",
    "\n",
    "  # The ENZYMES dataset\n",
    "  pyg_dataset= TUDataset(root, name)\n",
    "\n",
    "  # You will find that there are 600 graphs in this dataset\n",
    "  print(pyg_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NLm5vVYMAP2x"
   },
   "source": [
    "## Question 1: ENZYMES数据集中的类和特征的数量是多少?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iF_Kyqr_JbY"
   },
   "outputs": [],
   "source": [
    "def get_num_classes(pyg_dataset):\n",
    "  # TODO: Implement a function that takes a PyG dataset object\n",
    "  # and returns the number of classes for that dataset.\n",
    "\n",
    "  num_classes = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 line of code)\n",
    "  ## Note\n",
    "  ## 1. Colab autocomplete functionality might be useful.\n",
    "  num_classes = pyg_dataset.num_classes\n",
    "  #########################################\n",
    "\n",
    "  return num_classes\n",
    "\n",
    "def get_num_features(pyg_dataset):\n",
    "  # TODO: Implement a function that takes a PyG dataset object\n",
    "  # and returns the number of features for that dataset.\n",
    "\n",
    "  num_features = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 line of code)\n",
    "  ## Note\n",
    "  ## 1. Colab autocomplete functionality might be useful.\n",
    "  num_features = pyg_dataset.num_features\n",
    "  #########################################\n",
    "\n",
    "  return num_features\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  num_classes = get_num_classes(pyg_dataset)\n",
    "  num_features = get_num_features(pyg_dataset)\n",
    "  print(\"{} dataset has {} classes\".format(name, num_classes))\n",
    "  print(\"{} dataset has {} features\".format(name, num_features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rwKbzhHUAckZ"
   },
   "source": [
    "## PyG Data\n",
    "\n",
    "每个PyG dataset 都存储一个 `torch_geometric.data.Data` 列表中的objects，其中每个 `torch_geometric.data.Data` object 都表示一个图，我们能轻松通过dataset的index找到其中的 `Data` object\n",
    "\n",
    "有关`Data`对象中存储的内容等更多信息，请参阅[documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7sCV3xJWCddX"
   },
   "source": [
    "## Question 2: 在ENZYMES数据集中索引为100的图的标签是什么?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIis9oTZAfs3"
   },
   "outputs": [],
   "source": [
    "def get_graph_class(pyg_dataset, idx):\n",
    "  # TODO: Implement a function that takes a PyG dataset object,\n",
    "  # an index of a graph within the dataset, and returns the class/label\n",
    "  # of the graph (as an integer).\n",
    "\n",
    "  label = -1\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 line of code)\n",
    "  label = pyg_dataset[idx].y.item()\n",
    "  #########################################\n",
    "\n",
    "  return label\n",
    "\n",
    "# Here pyg_dataset is a dataset for graph classification\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  graph_0 = pyg_dataset[0]\n",
    "  print(graph_0)\n",
    "  idx = 100\n",
    "  label = get_graph_class(pyg_dataset, idx)\n",
    "  print('Graph with index {} has label {}'.format(idx, label))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fKhcVeAhCwoY"
   },
   "source": [
    "## Question 3: 索引为200的图有多少条边?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5m2DOfhBtWv"
   },
   "outputs": [],
   "source": [
    "def get_graph_num_edges(pyg_dataset, idx):\n",
    "  # TODO: Implement a function that takes a PyG dataset object,\n",
    "  # the index of a graph in the dataset, and returns the number of\n",
    "  # edges in the graph (as an integer). You should not count an edge\n",
    "  # twice if the graph is undirected. For example, in an undirected\n",
    "  # graph G, if two nodes v and u are connected by an edge, this edge\n",
    "  # should only be counted once.\n",
    "\n",
    "  num_edges = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## Note:\n",
    "  ## 1. You can't return the data.num_edges directly\n",
    "  ## 2. We assume the graph is undirected\n",
    "  ## 3. Look at the PyG dataset built in functions\n",
    "  ## (~4 lines of code)\n",
    "  graph = pyg_dataset[idx]\n",
    "  num_edges = graph.edge_index.size(1)\n",
    "  num_edges = num_edges//2\n",
    "  #########################################\n",
    "\n",
    "  return num_edges\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  idx = 200\n",
    "  num_edges = get_graph_num_edges(pyg_dataset, idx)\n",
    "  print('Graph with index {} has {} edges'.format(idx, num_edges))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AXa7yIG4E0Fp"
   },
   "source": [
    "# 2) Open Graph Benchmark (OGB)\n",
    "\n",
    "Open Graph Benchmark (OGB) 是一个现实的、大规模的、不同的基准数据集的集合，用于图上的机器学习。使用OGB Data Loader自动下载、处理和分割它的数据集。然后可以使用OGB评估器以统一的方式评估模型性能。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HnazPGGAJAZN"
   },
   "source": [
    "## Dataset and Data\n",
    "\n",
    "OGB还支持PyG数据集和数据类。下面我们来看一下`ogbn-arxiv`数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gpc6bTm3GF02"
   },
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  dataset_name = 'ogbn-arxiv'\n",
    "  # Load the dataset and transform it to sparse tensor\n",
    "  dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                  transform=T.ToSparseTensor())\n",
    "  print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n",
    "\n",
    "  # Extract the graph\n",
    "  data = dataset[0]\n",
    "  print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Cw0xZJKZI-n3"
   },
   "source": [
    "## Question 4: 在ogbn-arxiv图中有多少特征?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZP844_nT2ZJl"
   },
   "outputs": [],
   "source": [
    "def graph_num_features(data):\n",
    "  # TODO: Implement a function that takes a PyG data object,\n",
    "  # and returns the number of features in the graph (as an integer).\n",
    "\n",
    "  num_features = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 line of code)\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return num_features\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  num_features = graph_num_features(data)\n",
    "  print('The graph has {} features'.format(num_features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9DP_yEQZ0NVW"
   },
   "source": [
    "# 3) GNN: Node Property Prediction\n",
    "\n",
    "在本节中，我们将使用PyTorch Geometric构建我们的第一个图神经网络。然后我们将其应用于节点属性预测(节点分类)任务。\n",
    "\n",
    "具体来说，我们将使用GCN作为你的图神经网络的基础([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)). 为此，我们将使用PyG内置的`GCNConv`层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4CcOUEoInjD"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-DCtgcHpGIpd",
    "outputId": "4bb839e6-e04f-44d1-8f21-a976dd2b3b37"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)\n",
    "\n",
    "# The PyG built-in GCNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IK9z0wQIwzQ"
   },
   "source": [
    "## Load and Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ibJ0ieoIwQM",
    "outputId": "d482f6a2-a390-44b7-b562-1650476af6b4"
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  dataset_name = 'ogbn-arxiv'\n",
    "  dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                  transform=T.ToSparseTensor())\n",
    "  data = dataset[0]\n",
    "\n",
    "  # Make the adjacency matrix to symmetric\n",
    "  data.adj_t = data.adj_t.to_symmetric()\n",
    "\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "  # If you use GPU, the device should be cuda\n",
    "  print('Device: {}'.format(device))\n",
    "\n",
    "  data = data.to(device)\n",
    "  split_idx = dataset.get_idx_split()\n",
    "  train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OgUA815bNJ8w"
   },
   "source": [
    "## GCN Model\n",
    "\n",
    "## Question 5: 现在我们将实现我们的GCN模型!\n",
    "\n",
    "请按照下图实现`forward`功能。\n",
    "\n",
    "\n",
    "![test](./figure/GCN.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgspXTYpNJLA"
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout, return_embeds=False):\n",
    "        # TODO: Implement a function that initializes self.convs,\n",
    "        # self.bns, and self.softmax.\n",
    "\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # A list of GCNConv layers\n",
    "        self.convs = None\n",
    "\n",
    "        # A list of 1D batch normalization layers\n",
    "        self.bns = None\n",
    "\n",
    "        # The log softmax layer\n",
    "        self.softmax = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. You should use torch.nn.ModuleList for self.convs and self.bns\n",
    "        ## 2. self.convs has num_layers GCNConv layers\n",
    "        ## 3. self.bns has num_layers - 1 BatchNorm1d layers\n",
    "        ## 4. You should use torch.nn.LogSoftmax for self.softmax\n",
    "        ## 5. The parameters you can set for GCNConv include 'in_channels' and\n",
    "        ## 'out_channels'. For more information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n",
    "        ## 6. The only parameter you need to set for BatchNorm1d is 'num_features'\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "        ## (~10 lines of code)\n",
    "\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Skip classification layer and return node embeddings\n",
    "        self.return_embeds = return_embeds\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        # TODO: Implement a function that takes the feature tensor x and\n",
    "        # edge_index tensor adj_t and returns the output tensor as\n",
    "        # shown in the figure.\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Construct the network as shown in the figure\n",
    "        ## 2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch.org/docs/stable/nn.functional.html\n",
    "        ## 3. Don't forget to set F.dropout training to self.training\n",
    "        ## 4. If return_embeds is True, then skip the last softmax layer\n",
    "        ## (~7 lines of code)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FF1hnHUhO81e"
   },
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer, loss_fn):\n",
    "    # TODO: Implement a function that trains the model by\n",
    "    # using the given optimizer and loss_fn.\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. Zero grad the optimizer\n",
    "    ## 2. Feed the data into the model\n",
    "    ## 3. Slice the model output and label by train_idx\n",
    "    ## 4. Feed the sliced output and label to loss_fn\n",
    "    ## (~4 lines of code)\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJdlrJQhPBsK"
   },
   "outputs": [],
   "source": [
    "# Test function here\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator, save_model_results=False):\n",
    "    # TODO: Implement a function that tests the model by\n",
    "    # using the given split_idx and evaluator.\n",
    "    model.eval()\n",
    "\n",
    "    # The output of model on all data\n",
    "    out = None\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    ## Note:\n",
    "    ## 1. No index slicing here\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    if save_model_results:\n",
    "      print (\"Saving Model Predictions\")\n",
    "\n",
    "      data = {}\n",
    "      data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
    "\n",
    "      df = pd.DataFrame(data=data)\n",
    "      # Save locally as csv\n",
    "      df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)\n",
    "\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7F46xkuLiOL"
   },
   "outputs": [],
   "source": [
    "# Please do not change the args\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  args = {\n",
    "      'device': device,\n",
    "      'num_layers': 3,\n",
    "      'hidden_dim': 256,\n",
    "      'dropout': 0.5,\n",
    "      'lr': 0.01,\n",
    "      'epochs': 100,\n",
    "  }\n",
    "  args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dT8RyM2cPGxM"
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  model = GCN(data.num_features, args['hidden_dim'],\n",
    "              dataset.num_classes, args['num_layers'],\n",
    "              args['dropout']).to(device)\n",
    "  evaluator = Evaluator(name='ogbn-arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd5O5cnPPdVF"
   },
   "outputs": [],
   "source": [
    "# Please do not change these args\n",
    "# Training should take <10min using GPU runtime\n",
    "import copy\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  # reset the parameters to initial random value\n",
    "  model.reset_parameters()\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "  loss_fn = F.nll_loss\n",
    "\n",
    "  best_model = None\n",
    "  best_valid_acc = 0\n",
    "\n",
    "  for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    loss = train(model, data, train_idx, optimizer, loss_fn)\n",
    "    result = test(model, data, split_idx, evaluator)\n",
    "    train_acc, valid_acc, test_acc = result\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "          f'Loss: {loss:.4f}, '\n",
    "          f'Train: {100 * train_acc:.2f}%, '\n",
    "          f'Valid: {100 * valid_acc:.2f}% '\n",
    "          f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dQtt-EKA8P4r"
   },
   "source": [
    "## Question 6: 你的`best_model`验证和测试精度是多少?\n",
    "\n",
    "运行下面的单元格以查看最佳模型的结果，并将模型的预测保存到一个名为*ogbn-arxiv_node.csv*的文件中。在实验报告上报告结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqcextqOL2FX"
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  best_result = test(best_model, data, split_idx, evaluator, save_model_results=True)\n",
    "  train_acc, valid_acc, test_acc = best_result\n",
    "  print(f'Best model: '\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * valid_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "R8pOD6y80TyI"
   },
   "source": [
    "# 4) GNN: Graph Property Prediction\n",
    "\n",
    "在本节中，我们将创建一个用于图属性预测(图分类)的图神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRg5VOEdQTa4"
   },
   "source": [
    "## Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "LXb-O5QUIgTH",
    "outputId": "219cc8e6-1347-4401-e8b9-0c5e441d5534"
   },
   "outputs": [],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from torch_geometric.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  # Load the dataset\n",
    "  dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
    "\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "  print('Device: {}'.format(device))\n",
    "\n",
    "  split_idx = dataset.get_idx_split()\n",
    "\n",
    "  # Check task type\n",
    "  print('Task type: {}'.format(dataset.task_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cHHbgW1c5hi"
   },
   "outputs": [],
   "source": [
    "# Load the dataset splits into corresponding dataloaders\n",
    "# We will train the graph classification task on a batch of 32 graphs\n",
    "# Shuffle the order of graphs for training set\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n",
    "  valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)\n",
    "  test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYrSnOj0Y4DK"
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  # Please do not change the args\n",
    "  args = {\n",
    "      'device': device,\n",
    "      'num_layers': 5,\n",
    "      'hidden_dim': 256,\n",
    "      'dropout': 0.5,\n",
    "      'lr': 0.001,\n",
    "      'epochs': 30,\n",
    "  }\n",
    "  args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WLhguSTeazy"
   },
   "source": [
    "## Graph Prediction Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "u05Z14TRYPGn"
   },
   "source": [
    "### Graph Mini-Batching\n",
    "在深入研究实际模型之前，我们先介绍图的mini-batch概念。为了并行处理小批图，PyG将这些图组合成一个单独的断开连接的图数据对象(*torch_geometry.data. Batch*)。*torch_geometric.data.Batch*继承自*torch_geometry.data.Data*(前面介绍过)，并包含一个名为`batch`的附加属性。\n",
    "\n",
    "`batch`属性是一个向量，将每个节点映射到mini-batch中相应图的索引:\n",
    "\n",
    "    batch = [0, ..., 0, 1, ..., n - 2, n - 1, ..., n - 1]\n",
    "\n",
    "这个属性对于关联每个节点所属的图是至关重要的，并且可以用于对每个图的节点嵌入分别进行平均以计算图级嵌入。\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Pcic9NNU3nGK"
   },
   "source": [
    "## Question 7: 实现GCN图预测模型\n",
    "现在，我们有了实现GCN图预测模型的所有工具!\n",
    "\n",
    "我们将重用现有的GCN模型来生成`node_embeddings`，然后在节点上使用`Global Pooling`来创建可用于预测每个图的属性的图级嵌入。请记住，`batch`属性对于在我们的小批图上执行全局池至关重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_Kq3zyjeZ22"
   },
   "outputs": [],
   "source": [
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool\n",
    "\n",
    "### GCN to predict graph property\n",
    "class GCN_Graph(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(GCN_Graph, self).__init__()\n",
    "\n",
    "        # Load encoders for Atoms in molecule graphs\n",
    "        self.node_encoder = AtomEncoder(hidden_dim)\n",
    "\n",
    "        # Node embedding model\n",
    "        # Note that the input_dim and output_dim are set to hidden_dim\n",
    "        self.gnn_node = GCN(hidden_dim, hidden_dim,\n",
    "            hidden_dim, num_layers, dropout, return_embeds=True)\n",
    "\n",
    "        self.pool = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Initialize self.pool as a global mean pooling layer\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        # Output layer\n",
    "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      self.gnn_node.reset_parameters()\n",
    "      self.linear.reset_parameters()\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        # TODO: Implement a function that takes as input a\n",
    "        # mini-batch of graphs (torch_geometric.data.Batch) and\n",
    "        # returns the predicted graph property for each graph.\n",
    "        #\n",
    "        # NOTE: Since we are predicting graph level properties,\n",
    "        # your output will be a tensor with dimension equaling\n",
    "        # the number of graphs in the mini-batch\n",
    "\n",
    "\n",
    "        # Extract important attributes of our mini-batch\n",
    "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "        embed = self.node_encoder(x)\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Construct node embeddings using existing GCN model\n",
    "        ## 2. Use the global pooling layer to aggregate features for each individual graph\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n",
    "        ## 3. Use a linear layer to predict each graph's property\n",
    "        ## (~3 lines of code)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJjnGuMSbjX0"
   },
   "outputs": [],
   "source": [
    "def train(model, device, data_loader, optimizer, loss_fn):\n",
    "    # TODO: Implement a function that trains your model by\n",
    "    # using the given optimizer and loss_fn.\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n",
    "      batch = batch.to(device)\n",
    "\n",
    "      if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
    "          pass\n",
    "      else:\n",
    "        ## ignore nan targets (unlabeled) when computing training loss.\n",
    "        is_labeled = batch.y == batch.y\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Feed the data into the model\n",
    "        ## 3. Use `is_labeled` mask to filter output and labels\n",
    "        ## 4. You may need to change the type of label to torch.float32\n",
    "        ## 5. Feed the output and label to the loss_fn\n",
    "        ## (~3 lines of code)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztPHXq_Gzn7U"
   },
   "outputs": [],
   "source": [
    "# The evaluation function\n",
    "def eval(model, device, loader, evaluator, save_model_results=False, save_file=None):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch)\n",
    "\n",
    "            y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "            y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    if save_model_results:\n",
    "        print (\"Saving Model Predictions\")\n",
    "\n",
    "        # Create a pandas dataframe with a two columns\n",
    "        # y_pred | y_true\n",
    "        data = {}\n",
    "        data['y_pred'] = y_pred.reshape(-1)\n",
    "        data['y_true'] = y_true.reshape(-1)\n",
    "\n",
    "        df = pd.DataFrame(data=data)\n",
    "        # Save to csv\n",
    "        df.to_csv('ogbg-molhiv_graph_' + save_file + '.csv', sep=',', index=False)\n",
    "\n",
    "    return evaluator.eval(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MR1wQ4hMZeMw"
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  model = GCN_Graph(args['hidden_dim'],\n",
    "              dataset.num_tasks, args['num_layers'],\n",
    "              args['dropout']).to(device)\n",
    "  evaluator = Evaluator(name='ogbg-molhiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJGTNZiuZy0A"
   },
   "outputs": [],
   "source": [
    "# Please do not change these args\n",
    "# Training should take <10min using GPU runtime\n",
    "import copy\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  model.reset_parameters()\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "  loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "  best_model = None\n",
    "  best_valid_acc = 0\n",
    "\n",
    "  for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    print('Training...')\n",
    "    loss = train(model, device, train_loader, optimizer, loss_fn)\n",
    "\n",
    "    print('Evaluating...')\n",
    "    train_result = eval(model, device, train_loader, evaluator)\n",
    "    val_result = eval(model, device, valid_loader, evaluator)\n",
    "    test_result = eval(model, device, test_loader, evaluator)\n",
    "\n",
    "    train_acc, valid_acc, test_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric], test_result[dataset.eval_metric]\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "          f'Loss: {loss:.4f}, '\n",
    "          f'Train: {100 * train_acc:.2f}%, '\n",
    "          f'Valid: {100 * valid_acc:.2f}% '\n",
    "          f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6I17-Qso_n88"
   },
   "source": [
    "## Question 8: 你的`best_model`验证和测试ROC-AUC分数是多少?\n",
    "\n",
    "运行下面的单元格以查看最佳模型的结果，并将模型的预测保存在名为*ogbg-molhiv_graph_[valid,test].csv*的文件中。在实验报告上报告结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq5QaG21dOOO"
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  train_auroc = eval(best_model, device, train_loader, evaluator)[dataset.eval_metric]\n",
    "  valid_auroc = eval(best_model, device, valid_loader, evaluator, save_model_results=True, save_file=\"valid\")[dataset.eval_metric]\n",
    "  test_auroc  = eval(best_model, device, test_loader, evaluator, save_model_results=True, save_file=\"test\")[dataset.eval_metric]\n",
    "\n",
    "  print(f'Best model: '\n",
    "      f'Train: {100 * train_auroc:.2f}%, '\n",
    "      f'Valid: {100 * valid_auroc:.2f}% '\n",
    "      f'Test: {100 * test_auroc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
